<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Weizhi Wang, Rutgers grad student focused on Natural Language Processing & Deep Learning</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./assets_files/yangqing.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets_files/weizhi.ico">
</head>

<div class="visible-phone" id="blackBar">
    <a href="#top">About</a>
    <!--<a href="#research">Research</a>-->
    <a href="#publications">Publications</a>
    <a href="#projects">Projects</a>
    <a href="#Teaching">Teaching</a>
    <!--<a href="#teaching">Teaching</a>-->
    <a target="_blank"
       href="https://drive.google.com/file/d/1uFwIXjcfi4qiRIS9JIAz_MPH99WGpA2U/view?usp=sharing">CV</a>
</div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <!--<li><a href="#publications">Publications</a></li> -->
            <li><a href="#projects">Projects</a></li>
            <li><a href="#teaching">Teaching</a></li>
            <li><a target="_blank"
                   href="https://drive.google.com/file/d/1uFwIXjcfi4qiRIS9JIAz_MPH99WGpA2U/view?usp=sharing">CV</a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets_files/me.jpg" alt="photo" class="logo-image">
            <br><br>
            weizhi.wang AT rutgers.edu <br>
        </div>

        <!-- Otherwise, we simply use a flat list of links -->

    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                Weizhi Wang (王伟志)
            </h3>
            <h5>
                weizhi.wang AT rutgers.edu
            / <a target="_blank"
                 href="https://www.linkedin.com/in/weizhiwang">LinkedIn</a>
            / <a target="_blank" 
                 href="https://github.com/Victorwz">GitHub</a>
            / <a target="_blank"
                 href="https://drive.google.com/file/d/1uFwIXjcfi4qiRIS9JIAz_MPH99WGpA2U/view?usp=sharing">CV</a>
<!--             / <mark>actively looking for job</mark> -->
            </h5>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <a class="visible-phone pull-left" href="http://daggerfs.com/index.html#">
                <img class="media-object" src="assets_files/me.jpg" width="96px" style="margin: 0px 10px">
            </a>
            <p>
                I'm a master CS student from Rutgers, with my interest focus on Natural Language Processing and Deep Generative Model. I finished my four-year undergraduate study at Xi'an Jiaotong University in Xi'an, with a Bachelor Degree in Electrical Engineering. 
            </p>


            <!--
             *** Research ***
            -->
            <!--<h3>-->
            <!--<a name="research"></a> Research-->
            <!--</h3>-->
            <!--<p>-->
            <!--My current research topics include:-->
            <!--</p><ul>-->
            <!--<li> Learning better structures for image feature extraction.-->
            <!--</li><li> Explaining human generalization behavior with visually grounded cogscience models.-->
            <!--</li><li> Making large-scale vision feasible and affordable.-->
            <!--</li></ul>-->
            <!--<p></p>-->
            <!--<p> (Most recent publications to be added) </p>-->


            <!--
             *** Publications ***
            -->
<!--             <h3>
                <a name="publications"></a> Publications
            </h3>

                  <div class="media">
                <a name="fsaf" class="pull-left">
                    <img class="media-object" src="assets_files/gridcell.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Feature Selective Anchor-Free Module for Single-Shot Object Detection
                     </strong><br>
                        Tao Wang, Hui Cao, Xingyu Yan, Yanqing Ma, and <strong>Yihui He</strong>, , <a target="_blank" href="http://www.cmu-biometrics.org/">Marios Savvides</a>, <strong>CCC 2019</strong>
                        <a target="_blank"
                           href="https://arxiv.org/abs/1903.00621">[PDF]</a>  
                        
                        
                    </p>
                    <p class="abstract-text">
                        We motivate and present feature selective anchor-free (FSAF) module, a simple and effective building block forsingle-shot object detectors. It can be plugged into single-shot detectors with feature pyramid structure. The FSAF module addresses two limitations brought up by the conventional anchor-based detection: 1) heuristic-guided feature selection; 2) overlap-based anchor sampling. 
                    </p>
                </div>
            </div>
         <div class="media">
                <a name="softer" class="pull-left">
                    <img class="media-object" src="https://raw.githubusercontent.com/yihui-he/softer-NMS/master/demo/output/softer.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Bounding Box Regression with Uncertainty for Accurate Object Detection
                     </strong><br>
                        <strong>Yihui He</strong>, Chenchen Zhu, Jianren Wang, <a target="_blank" href="http://www.cmu-biometrics.org/">Marios Savvides</a>, Xiangyu Zhang, <strong>CVPR 2019</strong>
                        <a target="_blank"
                           href="https://arxiv.org/abs/1809.08545">[arXiv]</a>  
                        <a target="_blank"
                           href="https://www.youtube.com/watch?v=bcGtNdTzdkc">[presentation]</a>                          
                        <a target="_blank"
                           href="https://github.com/yihui-he/KL-Loss">[code]</a>  
                        
                        
                    </p>
                    <p class="abstract-text">
                        We introduce a novel bounding box regression loss for learning bounding box transformation and localization variance together. The resulting localization variance is utilized in our new non-maximum suppression method to improve localization accuracy for object detection. On MS-COCO, we boost the AP of VGG-16 faster R-CNN from 23.6% to 29.1% with a single model and nearly no additional computational overhead. More importantly, our method improves the AP of ResNet-50 FPN fast R-CNN from 36.8% to 37.8%, which achieves state-of-the-art bounding box refinement result.
                    </p>
                </div>
            </div> -->

                


            <!--<div class="media">-->
            <!--<a class="pull-left" href="#top">-->
            <!--<img class="media-object" src="./assets_files/decaf-features.png" width="96px" height="96px">-->
            <!--</a>-->
            <!--<div class="media-body">-->
            <!--<p class="media-heading">-->
            <!--<strong>DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition</strong><br>-->
            <!--J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, T Darrell. arXiv preprint.<br>-->
            <!--<a target="_blank" href="http://arxiv.org/abs/1310.1531">[ArXiv Link]</a>-->
            <!--<a target="_blank" href="http://decaf.berkeleyvision.org/">[Live Demo]</a>-->
            <!--<a target="_blank" href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a>-->
            <!--<a target="_blank" href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a>-->
            <!--</p>-->
            <!--<p class="abstract-text">-->
            <!--We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. We also released the software and pre-trained network to do large-scale image classification.-->
            <!--</p>-->
            <!--</div>-->
            <!--</div>-->

            <!--
             *** Projects ***
            -->
            <h3>
                <a name="projects"></a> Projects
            </h3>
            Link to my <a target="_blank" href="https://github.com/Victorwz">[github public projects]</a>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/htssa.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Hierarchical Fine-grained sentiment Classification Using BERT
                        </strong>
<!--                         <a target="_blank"
                           href="https://github.com/yihui-he/TSP">[Code]</a> -->
                    </p>
                    <p class="abstract-text">
                    We propose a hierarchical tree-structured sentiment classification model conjunction with the data augmentation approach, to solve the above data imbalance problem in fine-grained sentiment classification well. Our model deploys a tree-structured classification architecture, with every non-leaf tree node as a pre-trained BERT model. Our model can automatically transform fine-grained sentiment classification into hierarchical bi-classification or tri-classification tasks and complete the task through a decision tree structure. The experimental results demonstrate that our model has robust superiority over strong competitors and improve the fine-grained classification performance of BERT benchmark.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/gridcell.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Generative Hippocampal-entorhinal System
                        </strong>
                        <a target="_blank" href="https://github.com/Victorwz/Generative-Hippocampal-entorhinal-System">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        We build up a generative model and inference network with VAE to intimidate the grid cells and place cells in Hippocampal-entorhinal System of human.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object" 
                         src="assets_files/acc.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Fast Weights
                        </strong>
                        <a target="_blank" href="https://github.com/Victorwz/fast-weights-pytorch">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        I reimplemented the paper <a target="_blank" href="https://arxiv.org/abs/1610.06258.pdf">[Using Fast Weights to Attend to the Recent Past]</a> using PyTorch. The other public available reimplementations for this paper are using TensorFlow. The reimplemented accuracy of the information retrieval task in the source paper achieves 98%.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/crf.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Awesome NLP Models
                        </strong>
                        <a target="_blank" href="https://github.com/Victorwz/awesome_NLP_models">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        I reimplemented several classic NLP models using PyTorch, including HMM, Self-Attention, CRF, Log-Linear, Ngram.
                    </p>
                </div>
            </div>


            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/person.png" width="96px"
                         height="96px">
                </a>

                <div class="media-body">
                    <p class="media-heading">
                        <strong>Objects Detection with Faster-RCNN on Power Equipment</strong> 
                    </p>
                    <p class="abstract-text">
                        We implemented the Faster-RCNN network based on TensorFlow framework to realize object detection towards specific power equipment. We finished the labeling of the image data from scratch following PASCAL VOC standard. With the best parameters, we got 40% precision and 35% recall.
                    </p>
                </div>
            </div>

            

            <h3>
                <a name="teaching"></a> Teaching
            </h3>

             <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/cs188.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>Rutgers CS170: Computer Application for Business</strong>
                        <a target="_blank"
                                   href="https://www.cs.rutgers.edu/academics/undergraduate/course-synopses/course-details/01-198-170-computer-application-for-business">[Webpage]</a>
                    </p>
                    <p><strong>Teaching Assistant</strong> </p>
                    <p class="abstract-text">
                        Working with Prof. <a href="http://www.ftrees.com/">Frances Trees </a> and other excellent members in teaching team to provide high quality course on 
                        front-end development using HTML5, CSS, and JavaScript.
                    </p>
                </div>
            </div>


            <!-- Footer
            ================================================== -->
            <hr>
            <!-- <footer class="footer">
                <div class='hidden-phone'>
                <h3 class="text-center"><a name="wall"></a><strong>works</strong></h3>
                <section id="photos">
                    <img src="https://raw.githubusercontent.com/yihui-he/lip-tracking-with-snake-active-contour-and-particle-filter/master/pic.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/Edge-detection-with-zero-crossing/master/lena_1.bmp"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/3D-reconstruction/master/result/selfff.png"/>
                    <img src="./assets_files/cs188.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/person.jpg.png"/>
                    <img src="./assets_files/vehicle.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/Depth-estimation-with-neural-network/master/presentation/stereo.png?token=AJkBS_A-YWaMd9vcgEQuaXQWe9wmjtTBks5XWM07wA%3D%3D"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/deep-learning-guide/master/presentation/resnet.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/deep-learning-guide/master/presentation/kmeans.jpg"/>
                    <img src="./assets_files/shuttle.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/gaoxin.jpg"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/artwork.jpg"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/bop.jpg"/>
                    <img src="./assets_files/ocsi.png"/>
                </section>
                
                <a target="_blank" href="https://github.com/yihui-he/panorama"><img
                        src="https://github.com/yihui-he/panorama/blob/master/results/yellowstone5.jpg?raw=true"></a>
                <hr>
                </div> -->
                <div class="row">
                    <div class="span12">
                        <p>
                            modified from <a target="_blank" href="http://daggerfs.com/">© Yangqing Jia 2013</a>
                        </p>
                    </div>
                </div>

            </footer>
        </div>
    </div>
</div>
</body>
</html>

<!-- Le javascript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<!--
    <script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap-transition.js"></script>
    <script src="assets/js/bootstrap-alert.js"></script>
    <script src="assets/js/bootstrap-modal.js"></script>
    <script src="assets/js/bootstrap-dropdown.js"></script>
    <script src="assets/js/bootstrap-scrollspy.js"></script>
    <script src="assets/js/bootstrap-tab.js"></script>
    <script src="assets/js/bootstrap-tooltip.js"></script>
    <script src="assets/js/bootstrap-popover.js"></script>
    <script src="assets/js/bootstrap-button.js"></script>
    <script src="assets/js/bootstrap-collapse.js"></script>
    <script src="assets/js/bootstrap-carousel.js"></script>
    <script src="assets/js/bootstrap-typeahead.js"></script>
    <script src="assets/js/bootstrap-affix.js"></script>
    <script src="assets/js/holder/holder.js"></script>
    <script src="assets/js/application.js"></script>
-->
