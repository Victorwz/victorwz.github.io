<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Weizhi Wang, Rutgers grad student focused on Natural Language Processing & Deep Learning</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./assets_files/yangqing.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets_files/weizhi.ico">
</head>

<div class="visible-phone" id="blackBar">
    <a href="#top">About</a>
    <!--<a href="#research">Research</a>-->
    <a href="#publications">Publications</a>
    <a href="#projects">Projects</a>
    <a href="#Teaching">Teaching</a>
    <!--<a href="#teaching">Teaching</a>-->
    <a target="_blank"
       href="./addtional_files/CV_Weizhi Wang.pdf">CV</a>
</div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <li><a href="#publications">Publications</a></li>
            <li><a href="#projects">Projects</a></li>
            <li><a href="#teaching">Teaching</a></li>
            <li><a target="_blank"
                   href="./addtional_files/CV_Weizhi Wang.pdf">CV</a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets_files/me.jpg" alt="photo" class="logo-image">
            <br><br>
            weizhi.wang AT rutgers.edu <br>
        </div>

        <!-- Otherwise, we simply use a flat list of links -->

    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                Weizhi Wang (王伟志)
            </h3>
            <h5>
                weizhi.wang AT rutgers.edu
            / <a target="_blank"
                 href="https://www.linkedin.com/in/weizhiwang">LinkedIn</a>
            / <a target="_blank" 
                 href="https://github.com/Victorwz">GitHub</a>
            / <a target="_blank" 
                 href="https://scholar.google.com/citations?user=UC2_V1MAAAAJ">Google Scholar</a>
            / <a target="_blank"
                 href="./addtional_files/CV_Weizhi Wang.pdf">CV</a>
<!--             / <mark>actively looking for job</mark> -->
            </h5>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <a class="visible-phone pull-left" href="http://daggerfs.com/index.html#">
                <img class="media-object" src="assets_files/me.jpg" width="96px" style="margin: 0px 10px">
            </a>
            <p>
                I'm a master CS student from Rutgers University, US. Before that, I obtained Bachelor Degree in Electrical Engineering from Xi'an Jiaotong University.
                Currently, I work as a research intern at Alibaba DAMO Academy, mentored by <a target="_blank" href="https://zrustc.github.io/">Zhirui Zhang</a> and <a target="_blank" href="https://sites.google.com/site/chenboxing/Home">Boxing Chen</a>.
            </p>


            <!--
             *** Research ***
            -->
            <h3>
            <a name="research"></a> Research Focus
            </h3>
            <p>
            I am focusing on the field of natural language processing. My research focus and past experience can be summarized as the following aspects:
            </p><ul>
            <li> Dialogue Systems: knowledge-enhanced dialogue systems with pre-trained models.
            </li><li> Multilingual and Multimodal Translation: zero-shot/few-shot translation in large-scale multilingual translation systems; end-to-end speech-to-text translation.
            </li><li> Pre-trained Models: prompt-based fine-tuning; parameter-efficient fine-tuning with adapters.
            </li></ul>
            <p></p>
            <!-- <p> (Most recent publications to be added) </p> -->


            <!--
             *** Publications ***
            -->
            <h3>
                <a name="publications"></a> Publications
            </h3>

            <div class="media">
                <!-- <a name="fsaf" class="pull-left">
                    <img class="media-object" src="assets_files/emnlp2021_mnmt.png" width="96px" height="96px">
                </a> -->
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Rethinking Zero-shot Neural Machine Translation: From a Perspective of Latent Variables
                     </strong><br>
                        <strong>Weizhi Wang</strong>, <a target="_blank" href="https://zrustc.github.io/">Zhirui Zhang</a>, Yichao Du, Boxing Chen, Jun Xie, Weihua Luo. <br>
                        <strong>Findings of EMNLP 2021</strong>
                        <a target="_blank"
                           href="addtional_files/_EMNLP_2021__Rethinking_Zero_shot_Neural_Machine_Translation.pdf">[PDF]</a>  
                    </p>
                    <!-- <p class="abstract-text">
                        We propose to introduce a denoising autoencoder objective based on pivot language into traditional training objective to improve the translation accuary on zero-shot directions. The theoretical analysis based on the perspective of latent variables shows that our proposed approach actually implicitly maximizes the probability distributions for zero-shot translation direction. 
                    </p> -->
                </div>
            </div>

            <div class="media">
                <!-- <a name="fsaf" class="pull-left">
                    <img class="media-object" src="assets_files/emnlp2021_mnmt.png" width="96px" height="96px">
                </a> -->
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Blockchain-Based Botnets for Command-and-Control Resilience
                     </strong><br>
                        <strong>Weizhi Wang</strong>, Xiaobo Ma. <br>
                        <strong>Botnets. CRC Press. 2019.</strong>
                        <!-- <a target="_blank"
                           href="">[PDF]</a>   -->
                    </p>
                </div>
            </div>

            <div class="media">
                <!-- <a name="fsaf" class="pull-left">
                    <img class="media-object" src="assets_files/emnlp2021_mnmt.png" width="96px" height="96px">
                </a> -->
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Adaptive Region Growing For Unmanned System
                     </strong><br>
                     Tao Wang, Hui Cao, Xingyu Yan, Yanqing Ma, <strong>Weizhi Wang</strong>. <br>
                        <strong>CCC 2019.</strong>
                        <a target="_blank"
                           href="addtional_files/Adaptive_Region_Growing_For_Unmanned_System.pdf">[PDF]</a>  
                    </p>
                </div>
            </div>

            <h3>
                <a name="publications"></a> Preprints
            </h3>
            <div class="media">
                <!-- <a name="softer" class="pull-left">
                    <img class="media-object" src="assets_files/aaai2022_tod.png" width="96px" height="96px">
                </a> -->
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Task-Oriented Dialogue Systems as Natural Language Generation
                        </strong><br>
                        <strong>Weizhi Wang</strong>, <a target="_blank" href="https://zrustc.github.io/">Zhirui Zhang</a>, <a target="_blank" href="https://zrustc.github.io/">Junliang Guo</a>, Boxing Chen, Weihua Luo. <br>
                        <strong>Submitted to AAAI 2022.</strong>
                        <a target="_blank"
                           href="addtional_files/_AAAI_2022__Task_Oriented_Dialogue_System_as_Natural_Language_Generation.pdf">[PDF]</a>  
                        <!-- <a target="_blank"
                           href="https://www.youtube.com/watch?v=bcGtNdTzdkc">[presentation]</a>                          
                        <a target="_blank"
                           href="https://github.com/yihui-he/KL-Loss">[code]</a>   -->
                        
                        
                    </p>
                    <!-- <p class="abstract-text">
                        We propose to formulate the task-oriented dialogue system as the purely natural language generation task, so as to fully leverage the large-scale pre-trained models like GPT-2 and simplify complicated delexicalization prepossessing. 
                        However, directly applying this method heavily suffers from the dialogue entity inconsistency caused by the removal of delexicalized tokens, as well as the catastrophic forgetting problem of the pre-trained model during fine-tuning, leading to unsatisfactory performance.
                        To alleviate these problems, we design a novel GPT-Adapter-CopyNet network, which incorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve better performance on transfer learning and dialogue entity generation.
                    </p> -->
                </div>
            </div>
            <div class="media">
                <!-- <a name="softer" class="pull-left">
                    <img class="media-object" src="assets_files/aaai2022_tda.png" width="96px" height="96px">
                </a> -->
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Regularizing End-to-End Speech-to-text Translation with Triangular Decomposition Agreement
                        </strong><br>
                        Yichao Du, <a target="_blank" href="https://zrustc.github.io/">Zhirui Zhang</a>, <strong>Weizhi Wang</strong>, Boxing Chen, Jun Xie, Tong Xu, Weihua Luo, and Enhong Chen. <br>
                        <strong>Submitted to AAAI 2022.</strong>
                        <a target="_blank"
                           href="addtional_files/_AAAI_2022__ST_TDA.pdf">[PDF]</a>  
                        <!-- <a target="_blank"
                           href="https://www.youtube.com/watch?v=bcGtNdTzdkc">[presentation]</a>                          
                        <a target="_blank"
                           href="https://github.com/yihui-he/KL-Loss">[code]</a>   -->
                        
                        
                    </p>
                    <!-- <p class="abstract-text">
                        We introduce two Kullback-Leibler divergence regularization terms into the model training objective to reduce the mismatch between output probabilities of dual-path.
                        Then the well-trained model can be naturally transformed as the E2E-ST models by pre-defined early stop.
                        Experiments on the MuST-C benchmark demonstrate that our proposed approach significantly outperforms state-of-the-art E2E-ST baselines on all 8 language pairs, while achieving better performance in the automatic speech recognition task.
                    </p> -->
                </div>
            </div>
                


            <!--<div class="media">-->
            <!--<a class="pull-left" href="#top">-->
            <!--<img class="media-object" src="./assets_files/decaf-features.png" width="96px" height="96px">-->
            <!--</a>-->
            <!--<div class="media-body">-->
            <!--<p class="media-heading">-->
            <!--<strong>DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition</strong><br>-->
            <!--J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, T Darrell. arXiv preprint.<br>-->
            <!--<a target="_blank" href="http://arxiv.org/abs/1310.1531">[ArXiv Link]</a>-->
            <!--<a target="_blank" href="http://decaf.berkeleyvision.org/">[Live Demo]</a>-->
            <!--<a target="_blank" href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a>-->
            <!--<a target="_blank" href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a>-->
            <!--</p>-->
            <!--<p class="abstract-text">-->
            <!--We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. We also released the software and pre-trained network to do large-scale image classification.-->
            <!--</p>-->
            <!--</div>-->
            <!--</div>-->

            <!--
             *** Projects ***
            -->
            <h3>
                <a name="projects"></a> Projects
            </h3>
            Link to my <a target="_blank" href="https://github.com/Victorwz">[github public projects]</a>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/htssa.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Hierarchical Fine-grained Sentiment Classification Using BERT
                        </strong>
<!--                         <a target="_blank"
                           href="https://github.com/yihui-he/TSP">[Code]</a> -->
                    </p>
                    <p class="abstract-text">
                    We propose a hierarchical tree-structured sentiment classification model conjunction with the data augmentation approach, to solve the data imbalance problem in fine-grained sentiment classification. 
                    The proposed model deploys a tree-structured classification architecture, with every non-leaf tree node as a pre-trained BERT model. The proposed method can automatically transform fine-grained sentiment classification into hierarchical bi-classification or tri-classification tasks and complete the task through a decision tree structure. 
                    The experimental results demonstrate that proposed method improves the fine-grained classification performance of BERT-base baseline by 3.5%.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/gridcell.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Generative Hippocampal-entorhinal System
                        </strong>
                        <a target="_blank" href="https://github.com/Victorwz/Generative-Hippocampal-entorhinal-System">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        We build up a generative model and inference network with VAE to intimidate the grid cells and place cells in Hippocampal-entorhinal System of human.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object" 
                         src="assets_files/acc.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Fast Weights
                        </strong>
                        <a target="_blank" href="https://github.com/Victorwz/fast-weights-pytorch">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        I reimplemented the paper <a target="_blank" href="https://arxiv.org/abs/1610.06258.pdf">[Using Fast Weights to Attend to the Recent Past]</a> using PyTorch. The other public available reimplementations for this paper are using TensorFlow. The reimplemented accuracy of the information retrieval task in the source paper achieves 98%.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="assets_files/crf.png"
                         width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Awesome NLP Models
                        </strong>
                        <a target="_blank" href="https://github.com/Victorwz/awesome_NLP_models">[Code]</a>
                    </p>
                    <p class="abstract-text">
                        I reimplemented several classic NLP models using PyTorch, including HMM, Self-Attention, CRF, Log-Linear, Ngram.
                    </p>
                </div>
            </div>

            <h3>
                <a name="teaching"></a> Teaching
            </h3>

             <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/cs188.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>Rutgers CS170: Computer Application for Business</strong>
                        <a target="_blank"
                                   href="https://www.cs.rutgers.edu/academics/undergraduate/course-synopses/course-details/01-198-170-computer-application-for-business">[Webpage]</a>
                    </p>
                    <p><strong>Teaching Assistant</strong> </p>
                    <p class="abstract-text">
                        Working with Prof. <a href="http://www.ftrees.com/">Frances Trees </a> and other excellent members in teaching team to provide high quality course on 
                        front-end development using HTML5, CSS, and JavaScript.
                    </p>
                </div>
            </div>


            <!-- Footer
            ================================================== -->
            <hr>
            <!-- <footer class="footer">
                <div class='hidden-phone'>
                <h3 class="text-center"><a name="wall"></a><strong>works</strong></h3>
                <section id="photos">
                    <img src="https://raw.githubusercontent.com/yihui-he/lip-tracking-with-snake-active-contour-and-particle-filter/master/pic.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/Edge-detection-with-zero-crossing/master/lena_1.bmp"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/3D-reconstruction/master/result/selfff.png"/>
                    <img src="./assets_files/cs188.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/person.jpg.png"/>
                    <img src="./assets_files/vehicle.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/Depth-estimation-with-neural-network/master/presentation/stereo.png?token=AJkBS_A-YWaMd9vcgEQuaXQWe9wmjtTBks5XWM07wA%3D%3D"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/deep-learning-guide/master/presentation/resnet.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/deep-learning-guide/master/presentation/kmeans.jpg"/>
                    <img src="./assets_files/shuttle.png"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/gaoxin.jpg"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/artwork.jpg"/>
                    <img src="https://raw.githubusercontent.com/yihui-he/my-Notes/master/bop.jpg"/>
                    <img src="./assets_files/ocsi.png"/>
                </section>
                
                <a target="_blank" href="https://github.com/yihui-he/panorama"><img
                        src="https://github.com/yihui-he/panorama/blob/master/results/yellowstone5.jpg?raw=true"></a>
                <hr>
                </div> -->
                <div class="row">
                    <div class="span12">
                        <p>
                            modified from <a target="_blank" href="http://daggerfs.com/">© Yangqing Jia 2013</a>
                        </p>
                    </div>
                </div>

            </footer>
        </div>
    </div>
</div>
</body>
</html>

<!-- Le javascript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<!--
    <script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap-transition.js"></script>
    <script src="assets/js/bootstrap-alert.js"></script>
    <script src="assets/js/bootstrap-modal.js"></script>
    <script src="assets/js/bootstrap-dropdown.js"></script>
    <script src="assets/js/bootstrap-scrollspy.js"></script>
    <script src="assets/js/bootstrap-tab.js"></script>
    <script src="assets/js/bootstrap-tooltip.js"></script>
    <script src="assets/js/bootstrap-popover.js"></script>
    <script src="assets/js/bootstrap-button.js"></script>
    <script src="assets/js/bootstrap-collapse.js"></script>
    <script src="assets/js/bootstrap-carousel.js"></script>
    <script src="assets/js/bootstrap-typeahead.js"></script>
    <script src="assets/js/bootstrap-affix.js"></script>
    <script src="assets/js/holder/holder.js"></script>
    <script src="assets/js/application.js"></script>
-->
